<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Strands Voice Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
            color: #333;
        }

        .container {
            max-width: 800px;
            width: 100%;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
            display: flex;
            flex-direction: column;
            height: 90vh;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            text-align: center;
        }

        .header h1 {
            font-size: 24px;
            margin-bottom: 5px;
        }

        .status {
            padding: 10px 20px;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #dc3545;
            transition: background 0.3s;
        }

        .status-indicator.connected {
            background: #28a745;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .chat-container {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
            background: #f8f9fa;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 16px;
            border-radius: 12px;
            max-width: 80%;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            background: #667eea;
            color: white;
            margin-left: auto;
        }

        .message.assistant {
            background: white;
            border: 1px solid #e9ecef;
        }

        .message.system {
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            font-size: 14px;
            text-align: center;
            margin-left: auto;
            margin-right: auto;
        }

        .controls {
            padding: 20px;
            background: white;
            border-top: 1px solid #e9ecef;
            display: flex;
            gap: 10px;
            align-items: center;
        }

        button {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
            font-weight: 600;
        }

        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        .btn-connect {
            background: #28a745;
            color: white;
        }

        .btn-disconnect {
            background: #dc3545;
            color: white;
        }

        .btn-mic {
            background: #667eea;
            color: white;
            flex: 1;
            font-size: 18px;
        }

        .btn-mic.recording {
            background: #dc3545;
            animation: pulse 1s infinite;
        }

        .btn-interrupt {
            background: #ff6b6b;
            color: white;
        }

        input {
            flex: 1;
            padding: 12px;
            border: 2px solid #e9ecef;
            border-radius: 8px;
            font-size: 16px;
        }

        input:focus {
            outline: none;
            border-color: #667eea;
        }

        .audio-visualizer {
            height: 60px;
            background: #f8f9fa;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 2px;
            padding: 10px;
            border-radius: 8px;
            margin: 10px 0;
        }

        .audio-bar {
            width: 4px;
            height: 20px;
            background: #667eea;
            border-radius: 2px;
            transition: height 0.1s;
        }

        .settings {
            padding: 10px 20px;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }

        select {
            padding: 8px 12px;
            border: 2px solid #e9ecef;
            border-radius: 6px;
            font-size: 14px;
        }

        .config-input {
            flex: 1;
            min-width: 200px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé§ Strands Voice Chat</h1>
            <p>Real-time bidirectional voice conversation</p>
        </div>

        <div class="settings">
            <label>
                WebSocket URL:
                <input type="text" id="wsUrl" value="ws://localhost:8765" class="config-input">
            </label>
        </div>

        <div class="status">
            <div class="status-indicator" id="statusIndicator"></div>
            <span id="statusText">Disconnected</span>
        </div>

        <div class="audio-visualizer" id="visualizer" style="display: none;">
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
        </div>

        <div class="chat-container" id="chatContainer">
            <div class="message system">Welcome! Click Connect to start voice chat. Keep mic active for automatic interruption when you speak.</div>
        </div>

        <div class="controls">
            <button class="btn-connect" id="connectBtn" onclick="toggleConnection()">Connect</button>
            <button class="btn-mic" id="micBtn" onclick="toggleMicrophone()" disabled>üé§ Start Speaking (Auto-Interrupt Enabled)</button>
            <button class="btn-interrupt" onclick="sendInterrupt()" disabled id="interruptBtn">‚èπ Manual Interrupt</button>
        </div>
    </div>

    <script>
        // WebSocket connection
        let ws = null;
        let connected = false;

        // Audio context and streams
        let audioContext = null;
        let microphone = null;
        let processor = null;
        let recording = false;
        
        // Audio playback - precise scheduling with source tracking
        let playbackContext = null;
        let nextPlaybackTime = 0;  // Track precise scheduling time
        let isPlaybackActive = false;
        let scheduledSources = [];  // Track all scheduled sources for interruption

        // UI elements
        const statusIndicator = document.getElementById('statusIndicator');
        const statusText = document.getElementById('statusText');
        const chatContainer = document.getElementById('chatContainer');
        const connectBtn = document.getElementById('connectBtn');
        const micBtn = document.getElementById('micBtn');
        const interruptBtn = document.getElementById('interruptBtn');
        const wsUrlInput = document.getElementById('wsUrl');
        const visualizer = document.getElementById('visualizer');

        function toggleConnection() {
            if (connected) {
                disconnect();
            } else {
                connect();
            }
        }

        function connect() {
            const wsUrl = wsUrlInput.value;
            console.log('üîµ [CLIENT] Attempting to connect to:', wsUrl);
            addMessage('system', `Connecting to ${wsUrl}...`);
            
            ws = new WebSocket(wsUrl);
            console.log('üîµ [CLIENT] WebSocket object created, readyState:', ws.readyState);
            
            ws.onopen = () => {
                console.log('‚úÖ [CLIENT] WebSocket connection opened!');
                connected = true;
                statusIndicator.classList.add('connected');
                statusText.textContent = 'Connected';
                connectBtn.textContent = 'Disconnect';
                connectBtn.className = 'btn-disconnect';
                micBtn.disabled = false;
                interruptBtn.disabled = false;
                addMessage('system', 'Connected! You can now start speaking.');
            };
            
            ws.onmessage = (event) => {
                console.log('üì• [CLIENT] Received message from server, length:', event.data.length);
                try {
                    const data = JSON.parse(event.data);
                    console.log('üìã [CLIENT] Parsed message type:', data.type, 'full data:', data);
                    handleServerMessage(data);
                } catch (e) {
                    console.error('‚ùå [CLIENT] Error parsing JSON:', e, 'raw data:', event.data);
                }
            };
            
            ws.onerror = (error) => {
                console.error('‚ùå [CLIENT] WebSocket error:', error);
                addMessage('system', 'Connection error!');
            };
            
            ws.onclose = (event) => {
                console.log('üî¥ [CLIENT] WebSocket closed. Code:', event.code, 'Reason:', event.reason, 'Clean:', event.wasClean);
                connected = false;
                isPlaybackActive = false;  // Stop any playback
                statusIndicator.classList.remove('connected');
                statusText.textContent = 'Disconnected';
                connectBtn.textContent = 'Connect';
                connectBtn.className = 'btn-connect';
                micBtn.disabled = true;
                interruptBtn.disabled = true;
                if (recording) toggleMicrophone();
                clearPlaybackBuffer();  // Clear audio
                addMessage('system', 'Disconnected from server.');
            };
        }

        function disconnect() {
            if (ws) {
                ws.close();
                ws = null;
            }
        }

        function toggleMicrophone() {
            console.log('üîÑ [CLIENT] Toggle microphone. Current recording state:', recording);
            if (!recording) {
                startRecording();
            } else {
                stopRecording();
            }
        }

        async function startRecording() {
            console.log('üé§ [CLIENT] Starting recording...');
            try {
                console.log('üé§ [CLIENT] Requesting microphone access...');
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                console.log('‚úÖ [CLIENT] Microphone access granted');
                
                audioContext = new AudioContext({ sampleRate: 16000 });
                console.log('‚úÖ [CLIENT] AudioContext created, sample rate:', audioContext.sampleRate);
                
                microphone = audioContext.createMediaStreamSource(stream);
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                console.log('‚úÖ [CLIENT] Audio processor created (buffer size: 4096)');
                console.log('üîç [CLIENT] Processor onaudioprocess before assignment:', processor.onaudioprocess);
                
                let audioChunkCount = 0;
                processor.onaudioprocess = (e) => {
                    audioChunkCount++;
                    
                    // Log first 5 callbacks to debug
                    if (audioChunkCount <= 5) {
                        console.log(`üé§ [CLIENT] onaudioprocess callback #${audioChunkCount} - recording:${recording}, ws:${ws ? 'exists' : 'null'}, readyState:${ws?.readyState}`);
                    }
                    
                    if (recording && ws && ws.readyState === WebSocket.OPEN) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        
                        // Log first 10 chunks, then every 50th
                        if (audioChunkCount <= 10 || audioChunkCount % 50 === 0) {
                            console.log(`üé§ [CLIENT] Processing audio chunk #${audioChunkCount}, samples:`, inputData.length);
                        }
                        
                        // Convert float32 to int16
                        const int16Data = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            const s = Math.max(-1, Math.min(1, inputData[i]));
                            int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        
                        // Send audio to server
                        const audioBase64 = btoa(String.fromCharCode.apply(null, new Uint8Array(int16Data.buffer)));
                        
                        const audioMsg = {
                            type: 'audio',
                            audioData: audioBase64,
                            sampleRate: 16000,
                            channels: 1
                        };
                        
                        // Log first 10 sends, then every 50th
                        if (audioChunkCount <= 10 || audioChunkCount % 50 === 0) {
                            console.log(`üì§ [CLIENT] Sending audio to server (chunk #${audioChunkCount}), base64 length:`, audioBase64.length);
                        }
                        
                        ws.send(JSON.stringify(audioMsg));
                        
                        // Update visualizer
                        updateVisualizer(inputData);
                    }
                };
                
                console.log('üîç [CLIENT] Processor onaudioprocess after assignment:', typeof processor.onaudioprocess);
                
                microphone.connect(processor);
                processor.connect(audioContext.destination);
                console.log('üîó [CLIENT] Microphone connected to processor, processor connected to destination');
                console.log('üîç [CLIENT] Stream active:', stream.active, 'tracks:', stream.getTracks().map(t => ({enabled: t.enabled, readyState: t.readyState})));
                
                recording = true;
                console.log('‚úÖ [CLIENT] Set recording = true, ws.readyState:', ws?.readyState, '(1=OPEN)');
                
                micBtn.textContent = '‚èπ Stop (Auto-Interrupt Active)';
                micBtn.classList.add('recording');
                visualizer.style.display = 'flex';
                addMessage('system', 'üé§ Recording... Speak now!');
                console.log('‚úÖ [CLIENT] Recording started successfully');
                
                // Debug: Check if processor is working after 2 seconds
                setTimeout(() => {
                    console.log(`üîç [CLIENT] Debug check after 2s - audioChunkCount: ${audioChunkCount}, recording: ${recording}`);
                    if (audioChunkCount === 0) {
                        console.error('‚ùå [CLIENT] WARNING: No audio chunks processed after 2 seconds! onaudioprocess is NOT firing!');
                    }
                }, 2000);
                
            } catch (error) {
                console.error('‚ùå [CLIENT] Error accessing microphone:', error);
                addMessage('system', 'Error: Could not access microphone!');
            }
        }

        function stopRecording() {
            console.log('üõë [CLIENT] Stopping recording...');
            recording = false;
            
            if (processor) {
                processor.disconnect();
                processor = null;
                console.log('‚úÖ [CLIENT] Audio processor disconnected');
            }
            
            if (microphone) {
                microphone.disconnect();
                microphone = null;
                console.log('‚úÖ [CLIENT] Microphone disconnected');
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
                console.log('‚úÖ [CLIENT] AudioContext closed');
            }
            
            micBtn.textContent = 'üé§ Start Speaking (Auto-Interrupt Enabled)';
            micBtn.classList.remove('recording');
            visualizer.style.display = 'none';
            addMessage('system', 'Recording stopped.');
            console.log('‚úÖ [CLIENT] Recording stopped successfully');
        }

        function sendInterrupt() {
            console.log('‚è∏Ô∏è [CLIENT] Sending interrupt signal...');
            
            // Immediately clear local playback (don't wait for server)
            clearPlaybackBuffer();
            
            if (ws && ws.readyState === WebSocket.OPEN) {
                const msg = { type: 'interrupt' };
                console.log('üì§ [CLIENT] Sending interrupt message to server:', msg);
                ws.send(JSON.stringify(msg));
                addMessage('system', 'Interrupted!');
                console.log('‚úÖ [CLIENT] Interrupt signal sent to server');
            } else {
                console.warn('‚ö†Ô∏è [CLIENT] Cannot send interrupt - WebSocket not open. State:', ws?.readyState);
                addMessage('system', 'Playback stopped (offline)');
            }
        }

        function disconnect() {
            console.log('üî¥ [CLIENT] Disconnecting...');
            if (ws) {
                ws.close();
                ws = null;
                console.log('‚úÖ [CLIENT] WebSocket closed');
            }
        }

        function handleServerMessage(data) {
            console.log('üìã [CLIENT] Handling server message type:', data.type);
            switch (data.type) {
                case 'connected':
                    console.log('‚úÖ [CLIENT] Server confirms connection:', data);
                    break;
                
                case 'audio':
                    console.log('üîä [CLIENT] Received audio from server, base64 length:', data.audioData?.length, 'sample rate:', data.sampleRate);
                    playAudioData(data.audioData, data.sampleRate || 24000);
                    break;
                
                case 'text':
                    console.log('üí¨ [CLIENT] Received text from server:', data.text?.substring(0, 50) + '...');
                    addMessage(data.role || 'assistant', data.text);
                    break;
                
                case 'interrupted':
                    const reason = data.reason === 'voice_activity_detected' ? 
                        '‚ö° Auto-Interrupt (You Started Speaking)' : 'Interrupted';
                    console.log('‚è∏Ô∏è [CLIENT] Received interrupt confirmation, reason:', data.reason || 'manual');
                    addMessage('system', reason);
                    clearPlaybackBuffer();
                    break;
                
                case 'tool_use':
                    console.log('üõ†Ô∏è [CLIENT] Tool usage:', data.name);
                    addMessage('system', `üõ† Using tool: ${data.name}`);
                    break;
                
                case 'connection_start':
                    console.log('üîó [CLIENT] Agent session started');
                    addMessage('system', 'Agent session started');
                    break;
                
                case 'connection_end':
                    console.log('üîó [CLIENT] Agent session ended');
                    addMessage('system', 'Agent session ended');
                    break;
                
                default:
                    console.warn('‚ö†Ô∏è [CLIENT] Unknown message type:', data.type, 'full data:', data);
            }
        }

        // Initialize playback context with precise scheduling
        function initPlaybackContext(sampleRate) {
            if (!playbackContext || playbackContext.sampleRate !== sampleRate) {
                console.log('üîä [CLIENT] Initializing playback context, sample rate:', sampleRate);
                
                if (playbackContext) {
                    try {
                        playbackContext.close();
                    } catch (e) {
                        console.warn('‚ö†Ô∏è [CLIENT] Error closing old context:', e);
                    }
                }
                
                playbackContext = new (window.AudioContext || window.webkitAudioContext)({ 
                    sampleRate: sampleRate,
                    latencyHint: 'interactive'
                });
                nextPlaybackTime = playbackContext.currentTime;
                isPlaybackActive = true;
                scheduledSources = [];  // Reset tracked sources
                
                console.log('‚úÖ [CLIENT] Playback context initialized, currentTime:', playbackContext.currentTime);
            }
        }
        
        // Play audio with precise Web Audio scheduling (like Python's sounddevice callback)
        async function playAudioData(audioBase64, sampleRate) {
            console.log('üîä [CLIENT] Scheduling audio chunk, base64 length:', audioBase64?.length, 'sample rate:', sampleRate);
            try {
                // Initialize playback context if needed
                initPlaybackContext(sampleRate);
                
                // Decode base64 to bytes
                const audioData = atob(audioBase64);
                const arrayBuffer = new ArrayBuffer(audioData.length);
                const view = new Uint8Array(arrayBuffer);
                
                for (let i = 0; i < audioData.length; i++) {
                    view[i] = audioData.charCodeAt(i);
                }
                
                // Convert int16 to float32
                const int16Array = new Int16Array(arrayBuffer);
                const float32Array = new Float32Array(int16Array.length);
                
                for (let i = 0; i < int16Array.length; i++) {
                    float32Array[i] = int16Array[i] / 32768.0;
                }
                
                // Create audio buffer
                const audioBuffer = playbackContext.createBuffer(1, float32Array.length, sampleRate);
                audioBuffer.getChannelData(0).set(float32Array);
                
                console.log('üîä [CLIENT] Audio buffer created, duration:', audioBuffer.duration.toFixed(3), 's, samples:', float32Array.length);
                
                // Create source and schedule playback
                const source = playbackContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(playbackContext.destination);
                
                // Track source for interruption
                scheduledSources.push(source);
                
                // Remove from tracking when finished
                source.onended = () => {
                    const index = scheduledSources.indexOf(source);
                    if (index > -1) {
                        scheduledSources.splice(index, 1);
                    }
                };
                
                // Precise scheduling using Web Audio API clock
                const currentTime = playbackContext.currentTime;
                const startTime = Math.max(currentTime, nextPlaybackTime);
                
                console.log('üîä [CLIENT] Scheduling playback at', startTime.toFixed(3), '(current:', currentTime.toFixed(3), ', next:', nextPlaybackTime.toFixed(3), ')');
                
                source.start(startTime);
                
                // Update next playback time for seamless queueing
                nextPlaybackTime = startTime + audioBuffer.duration;
                
                console.log('‚úÖ [CLIENT] Audio scheduled, next time:', nextPlaybackTime.toFixed(3), 'tracked sources:', scheduledSources.length);
                
            } catch (error) {
                console.error('‚ùå [CLIENT] Error scheduling audio:', error);
            }
        }
        
        // Clear all scheduled audio (for interruptions)
        function clearPlaybackBuffer() {
            console.log('üõë [CLIENT] Clearing playback, stopping', scheduledSources.length, 'scheduled sources');
            
            // Stop all scheduled sources immediately
            for (const source of scheduledSources) {
                try {
                    source.stop();
                    console.log('‚úÖ [CLIENT] Stopped source');
                } catch (e) {
                    // Source might have already finished or not started yet
                    console.log('‚ö†Ô∏è [CLIENT] Could not stop source:', e.message);
                }
            }
            scheduledSources = [];
            
            if (playbackContext) {
                try {
                    playbackContext.close();
                    console.log('‚úÖ [CLIENT] Context closed');
                } catch (e) {
                    console.warn('‚ö†Ô∏è [CLIENT] Error closing context:', e);
                }
                playbackContext = null;
                nextPlaybackTime = 0;
                isPlaybackActive = false;
            }
            console.log('‚úÖ [CLIENT] Playback cleared completely');
        }

        function updateVisualizer(audioData) {
            const bars = visualizer.querySelectorAll('.audio-bar');
            const rms = Math.sqrt(audioData.reduce((sum, val) => sum + val * val, 0) / audioData.length);
            const dbLevel = 20 * Math.log10(rms + 0.0001);
            const normalizedLevel = Math.max(0, Math.min(1, (dbLevel + 60) / 60));
            
            bars.forEach((bar, i) => {
                const height = 20 + (normalizedLevel * 40) * (1 - (i * 0.1));
                bar.style.height = `${height}px`;
            });
        }

        function addMessage(role, text) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            messageDiv.textContent = text;
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }
    </script>
</body>
</html>
